{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "from keras.layers import Input, Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import backend as k\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.manifold import TSNE\n",
    "from IPython.display import clear_output\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = {'agricultural':0, 'airplane':1, 'baseballdiamond':3, 'beach':4, 'buildings':5, 'chaparral':6, \n",
    "          'denseresidential':7, 'forest':8, 'freeway':9, 'golfcourse':10, 'harbor':11, 'intersection':12,\n",
    "         'mediumresidential':13, 'mobilehomepark':15, 'overpass':16, 'parkinglot':17, 'river':18,\n",
    "         'runway':18, 'sparseresidential':19, 'storagetanks':20, 'tenniscourt':21, }\n",
    "\n",
    "def load_images(dataset_path, total_images, labels, input_shape):\n",
    "    print(input_shape)\n",
    "    w = input_shape[0]\n",
    "    h = input_shape[1]\n",
    "    print(w,h)\n",
    "    shape = (total_images+1,input_shape[0],input_shape[1],input_shape[2])\n",
    "    y_shape = (total_images+1,1)\n",
    "    x = np.zeros(shape)\n",
    "    y = np.zeros(y_shape)\n",
    "    folders = os.listdir(dataset_path)\n",
    "    i = 0\n",
    "    h = 0\n",
    "    for folder in folders:\n",
    "        folder_path = os.path.join(dataset_path, folder)\n",
    "        images = os.listdir(folder_path)\n",
    "        h+=1\n",
    "        for image in images:\n",
    "            # Lembrando que todas as imagens possuem o formato labelxx.jpg\n",
    "#             print(image)\n",
    "#             print(folder)\n",
    "            image_path = os.path.join(folder_path,image)\n",
    "            img_np = cv2.imread(image_path)\n",
    "            img_np = np.resize(img_np, input_shape)\n",
    "            #print(img_np.shape)\n",
    "            x[i] = img_np\n",
    "            y[i] = np.array( int(labels[folder]) )\n",
    "            i+=1\n",
    "            del img_np\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Train(net, x_train, y_train_h, x_test, y_test_h, batch_size, epochs): \n",
    "  \n",
    "    #Computing the number of batchs\n",
    "    n_batchs_tr = x_train.shape[0]//batch_size\n",
    "    n_batchs_ts = x_test.shape[0]//batch_size\n",
    "    \n",
    "    acc_train = []\n",
    "    loss_train = []\n",
    "    acc_test = []\n",
    "    loss_test = []\n",
    "    \n",
    "    print('Start the training')\n",
    "    for epoch in range(epochs):\n",
    "        loss_tr = np.zeros((1 , 2))\n",
    "        loss_ts = np.zeros((1 , 2))\n",
    "        #Random shuffle the train data \n",
    "        x_train , y_train_h = shuffle(x_train , y_train_h , random_state = 0)\n",
    "\n",
    "        # Training the network per batch\n",
    "        for  batch in range(n_batchs_tr):\n",
    "\n",
    "            x_train_b = x_train[batch * batch_size : (batch + 1) * batch_size , : , : , :]\n",
    "            y_train_h_b = y_train_h[batch * batch_size : (batch + 1) * batch_size , : ]\n",
    "\n",
    "            loss_tr = loss_tr + net.train_on_batch(x_train_b , y_train_h_b)\n",
    "\n",
    "        acc_train.append(100*(loss_tr[0,1]/n_batchs_tr))\n",
    "        loss_train.append(loss_tr[0,0]/n_batchs_tr)\n",
    "\n",
    "        loss_tr = loss_tr/n_batchs_tr\n",
    "\n",
    "        # Evaluating the network in the test set\n",
    "        for  batch in range(n_batchs_ts):\n",
    "\n",
    "            x_test_b = x_test[batch * batch_size : (batch + 1) * batch_size , : , : , :]\n",
    "            y_test_h_b = y_test_h[batch * batch_size : (batch + 1) * batch_size , : ]\n",
    "\n",
    "            loss_ts = loss_ts + net.test_on_batch(x_test_b , y_test_h_b)\n",
    "\n",
    "        acc_test.append(100*(loss_ts[0,1]/n_batchs_ts))\n",
    "        loss_test.append(loss_ts[0,0]/n_batchs_ts)\n",
    "\n",
    "        loss_ts = loss_ts/n_batchs_ts\n",
    "\n",
    "        print(\"%d [Train loss: %f , Train acc.: %.2f%%][Test loss: %f , Test acc.:%.2f%%]\"\n",
    "             %(epoch , loss_tr[0 , 0], 100*loss_tr[0 , 1] , loss_ts[0 , 0] , 100 * loss_ts[0 , 1]))  \n",
    "\n",
    "        #Visualize Results every 5 epochs\n",
    "        if epoch>1 and epoch%5==0:\n",
    "            graph_training_history(acc_train, acc_test, loss_train, loss_test)\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 64, 3)\n",
      "64 64\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-02195c0742d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtrain_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/thimabru/Deep_Learning_aula/aula4/cyberlab_mission/UCMERCED_HW_SceneClassification/data/separated_in_labels/train\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mtotal_train_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1332\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_train_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/home/thimabru/Deep_Learning_aula/aula4/cyberlab_mission/UCMERCED_HW_SceneClassification/data/separated_in_labels/val\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-5da0f2d233da>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(dataset_path, total_images, labels, input_shape)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_images\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0my_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtotal_images\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mfolders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__=='__main__':\n",
    "  \n",
    "    # Define shapes\n",
    "    input_shape = (64 , 64 , 3)\n",
    "    classes = 21\n",
    "    \n",
    "    #Loading the data set\n",
    "    train_path = \"/home/thimabru/Deep_Learning_aula/aula4/cyberlab_mission/UCMERCED_HW_SceneClassification/data/separated_in_labels/train\"\n",
    "    total_train_images = 1332 - 1\n",
    "    x_train, y_train = load_images(train_path, total_train_images, labels, input_shape)\n",
    "\n",
    "    test_path = \"/home/thimabru/Deep_Learning_aula/aula4/cyberlab_mission/UCMERCED_HW_SceneClassification/data/separated_in_labels/val\"\n",
    "    total_test_images = 363 - 1\n",
    "    x_test, y_test = load_images(test_path, total_train_images, labels, input_shape)\n",
    "    \n",
    "    print(y_train.shape)\n",
    "\n",
    "    #Normalizing the set\n",
    "    x_train = x_train.astype('float32')/255.\n",
    "    x_test = x_test.astype('float32')/255.\n",
    "    \n",
    "    y_train = y_train.astype('uint8')\n",
    "    y_test = y_test.astype('uint8')\n",
    "\n",
    "    #Performing hot encoding\n",
    "    y_train_h = keras.utils.to_categorical(y_train , classes)\n",
    "    y_test_h = keras.utils.to_categorical(y_test , classes)\n",
    "    \n",
    "\n",
    "\n",
    "    ############ Change here  #########\n",
    "    lr = 1e-4\n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    adam = Adam(lr = lr)\n",
    "\n",
    "    # Create network\n",
    "    net = CNN(input_shape, classes)\n",
    "    net.compile(loss = 'categorical_crossentropy', optimizer=adam , metrics=['accuracy'])\n",
    "    net.summary()\n",
    "\n",
    "    #Call the train function  \n",
    "    net = Train(net, x_train, y_train_h, x_test, y_test_h, batch_size, epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
